{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import Cleaned Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import cleaned dataset using load_sets function defined in src.data.sets\n",
    "import sys\n",
    "sys.path.insert(1, '..')\n",
    "from src.data.sets import load_sets\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_sets(path='../data/processed/beer_type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import `torch`, `torch.nn` as `nn` and `torch.nn.functional` as `F`# Solution:\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate `PytorchBinary` with the correct number of input feature and save it into a variable called `model`\n",
    "\n",
    "# Solution:\n",
    "import sys\n",
    "sys.path.insert(1, '..')\n",
    "\n",
    "from src.models.pytorch import PytorchMultiClass\n",
    "\n",
    "model = PytorchMultiClass(X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PytorchMultiClass(\n",
       "  (layer_1): Linear(in_features=9, out_features=32, bias=True)\n",
       "  (layer_out): Linear(in_features=32, out_features=104, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import `get_device()` from `src.models.pytorch` and set `model` to use the device available\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1,'..')\n",
    "\n",
    "from src.models.pytorch import get_device\n",
    "\n",
    "device = get_device()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PytorchMultiClass(\n",
      "  (layer_1): Linear(in_features=9, out_features=32, bias=True)\n",
      "  (layer_out): Linear(in_features=32, out_features=104, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#Print the architecture of `model`\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate a `nn.BCELoss()` and save it into a variable called `criterion` \n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate a `torch.optim.Adam()` optimizer with the model's parameters and 0.001 as learning rate and save it into a variable called `optimizer`\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate a torch.optim.lr_scheduler.StepLR() scheduler that will decrease the learning rate by a coefficient of 0.9 for each epoch\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create 2 variables called N_EPOCHS and BATCH_SIZE that will take respectively 5 and 32 as values\n",
    "\n",
    "N_EPOCHS = 5\n",
    "BATCH_SIZE = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Dataset and DataLoader from torch.utils.data\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "#Import this class from `src/models/pytorch` and convert all sets to PytorchDataset\n",
    "from src.models.pytorch import PytorchDataset\n",
    "\n",
    "train_dataset = PytorchDataset(X=X_train, y=y_train)\n",
    "val_dataset = PytorchDataset(X=X_val, y=y_val)\n",
    "test_dataset = PytorchDataset(X=X_test, y=y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "\t(train)\t|\tLoss: 0.1306\t|\tAcc: 7.4%\n",
      "\t(valid)\t|\tLoss: 0.1309\t|\tAcc: 7.4%\n",
      "Epoch: 1\n",
      "\t(train)\t|\tLoss: 0.1309\t|\tAcc: 7.1%\n",
      "\t(valid)\t|\tLoss: 0.1307\t|\tAcc: 7.4%\n",
      "Epoch: 2\n",
      "\t(train)\t|\tLoss: 0.1309\t|\tAcc: 7.1%\n",
      "\t(valid)\t|\tLoss: 0.1311\t|\tAcc: 7.4%\n",
      "Epoch: 3\n",
      "\t(train)\t|\tLoss: 0.1309\t|\tAcc: 7.1%\n",
      "\t(valid)\t|\tLoss: 0.1310\t|\tAcc: 7.4%\n",
      "Epoch: 4\n",
      "\t(train)\t|\tLoss: 0.1309\t|\tAcc: 7.1%\n",
      "\t(valid)\t|\tLoss: 0.1307\t|\tAcc: 7.4%\n",
      "Epoch: 5\n",
      "\t(train)\t|\tLoss: 0.1309\t|\tAcc: 7.1%\n",
      "\t(valid)\t|\tLoss: 0.1307\t|\tAcc: 7.4%\n",
      "Epoch: 6\n",
      "\t(train)\t|\tLoss: 0.1309\t|\tAcc: 7.2%\n",
      "\t(valid)\t|\tLoss: 0.1307\t|\tAcc: 7.4%\n",
      "Epoch: 7\n",
      "\t(train)\t|\tLoss: 0.1309\t|\tAcc: 7.1%\n",
      "\t(valid)\t|\tLoss: 0.1311\t|\tAcc: 7.4%\n",
      "Epoch: 8\n",
      "\t(train)\t|\tLoss: 0.1309\t|\tAcc: 7.1%\n",
      "\t(valid)\t|\tLoss: 0.1311\t|\tAcc: 7.4%\n",
      "Epoch: 9\n",
      "\t(train)\t|\tLoss: 0.1309\t|\tAcc: 7.1%\n",
      "\t(valid)\t|\tLoss: 0.1310\t|\tAcc: 7.4%\n",
      "Epoch: 10\n",
      "\t(train)\t|\tLoss: 0.1309\t|\tAcc: 7.1%\n",
      "\t(valid)\t|\tLoss: 0.1309\t|\tAcc: 5.4%\n",
      "Epoch: 11\n",
      "\t(train)\t|\tLoss: 0.1309\t|\tAcc: 7.1%\n",
      "\t(valid)\t|\tLoss: 0.1307\t|\tAcc: 7.4%\n",
      "Epoch: 12\n",
      "\t(train)\t|\tLoss: 0.1309\t|\tAcc: 7.1%\n",
      "\t(valid)\t|\tLoss: 0.1309\t|\tAcc: 7.4%\n",
      "Epoch: 13\n",
      "\t(train)\t|\tLoss: 0.1309\t|\tAcc: 7.1%\n",
      "\t(valid)\t|\tLoss: 0.1307\t|\tAcc: 7.4%\n",
      "Epoch: 14\n",
      "\t(train)\t|\tLoss: 0.1309\t|\tAcc: 7.2%\n",
      "\t(valid)\t|\tLoss: 0.1311\t|\tAcc: 5.4%\n",
      "Epoch: 15\n",
      "\t(train)\t|\tLoss: 0.1309\t|\tAcc: 7.1%\n",
      "\t(valid)\t|\tLoss: 0.1306\t|\tAcc: 7.4%\n",
      "Epoch: 16\n",
      "\t(train)\t|\tLoss: 0.1309\t|\tAcc: 7.1%\n",
      "\t(valid)\t|\tLoss: 0.1310\t|\tAcc: 7.4%\n",
      "Epoch: 17\n",
      "\t(train)\t|\tLoss: 0.1309\t|\tAcc: 7.1%\n",
      "\t(valid)\t|\tLoss: 0.1306\t|\tAcc: 7.4%\n",
      "Epoch: 18\n",
      "\t(train)\t|\tLoss: 0.1309\t|\tAcc: 7.1%\n",
      "\t(valid)\t|\tLoss: 0.1310\t|\tAcc: 7.4%\n",
      "Epoch: 19\n",
      "\t(train)\t|\tLoss: 0.1309\t|\tAcc: 7.1%\n",
      "\t(valid)\t|\tLoss: 0.1313\t|\tAcc: 5.4%\n"
     ]
    }
   ],
   "source": [
    "#Create a for loop that will iterate through the specified number of epochs and will train the model with the training set and assess the performance on the validation set and print their scores\n",
    "\n",
    "from src.models.pytorch import train_classification, test_classification\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss, train_acc = train_classification(train_dataset, model=model, criterion=criterion, optimizer=optimizer, batch_size=BATCH_SIZE, device=device)\n",
    "    valid_loss, valid_acc = test_classification(val_dataset, model=model, criterion=criterion, batch_size=BATCH_SIZE, device=device)\n",
    "\n",
    "    print(f'Epoch: {epoch}')\n",
    "    print(f'\\t(train)\\t|\\tLoss: {train_loss:.4f}\\t|\\tAcc: {train_acc * 100:.1f}%')\n",
    "    print(f'\\t(valid)\\t|\\tLoss: {valid_loss:.4f}\\t|\\tAcc: {valid_acc * 100:.1f}%')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our baseline model and NN perform similarly and poorly. This is likely due to the large number of classes that need to be predicted (104 for the target variable). **Note: If permitted by Anthony/William, configure to top 20-30 classes by frequency and run the model again to see if performance has improved**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the model into the models folder\n",
    "\n",
    "torch.save(model, \"../models/neural_network\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.1312\t|\tAccuracy: 0.1\n"
     ]
    }
   ],
   "source": [
    "#Assess the model performance on the testing set and print its scores\n",
    "\n",
    "test_loss, test_acc = test_classification(test_dataset, model=model, criterion=criterion, batch_size=BATCH_SIZE, device=device)\n",
    "print(f'\\tLoss: {test_loss:.4f}\\t|\\tAccuracy: {test_acc:.1f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (tags/v3.8.10:3d8993a, May  3 2021, 11:48:03) [MSC v.1928 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "93e5285b5ee05b08152baf054ff49b5b3546c84ca307065b8c0361b70cc13ad6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
